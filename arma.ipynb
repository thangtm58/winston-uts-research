{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, time, copy\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy.stats as sps_autograd\n",
    "from autograd import grad, hessian\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate ARMA data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate ARMA(3, 2) model\n",
    "\"\"\"\n",
    "\n",
    "# Define AR and MA coefficients\n",
    "ar = np.array([1, -0.5, 0.3, -0.2])  \n",
    "ma = np.array([1, 0.4, -0.2])        \n",
    "\n",
    "# Create ARMA process object\n",
    "arma_process = ArmaProcess(ar, ma)\n",
    "\n",
    "# Simulate 1000 samples\n",
    "N = 1000\n",
    "y = arma_process.generate_sample(nsample=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karman Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_FGHQ(a, b):\n",
    "    \"\"\"\n",
    "    Construct the state-space matrices F, G, H for an ARMA(p, q) model.\n",
    "\n",
    "    Parameters:\n",
    "    - p: int, order of the AR component\n",
    "    - q: int, order of the MA component\n",
    "    - a: list or np.array of AR coefficients [a1, a2, ..., ap]\n",
    "    - b: list or np.array of MA coefficients [b1, b2, ..., bq]\n",
    "\n",
    "    Returns:\n",
    "    - F: state transition matrix of shape (k, k)\n",
    "    - G: noise coefficient matrix of shape (k, 1)\n",
    "    - H: observation matrix of shape (1, k)\n",
    "    - Q: covariance identity matrix of shape (k, k)\n",
    "    \"\"\"\n",
    "    p = len(a)\n",
    "    q = len(b)\n",
    "    k = max(p, q + 1)  # dimension of the state vector\n",
    "    F = np.zeros((k, k))\n",
    "    G = np.zeros((k, 1))\n",
    "    H = np.zeros((1, k))\n",
    "\n",
    "    # Fill the first column of F with AR coefficients\n",
    "    for i in range(p):\n",
    "        F[i, 0] = a[i]\n",
    "\n",
    "    # Fill the lower subdiagonal of F with 1s (shifting the state)\n",
    "    for i in range(k - 1):\n",
    "        F[i, i + 1] = 1\n",
    "\n",
    "    # Fill G with negative MA coefficients, first element = 1\n",
    "    for i in range(q):\n",
    "        G[i+1, 0] = -b[i]\n",
    "    G[0, 0] = 1  # first element always set to 1\n",
    "\n",
    "    # Matrix H: only first element is 1\n",
    "    H[0, 0] = 1\n",
    "\n",
    "    # Initialize covariance matrix Q as identity matrix\n",
    "    Q = np.eye(k)\n",
    "\n",
    "    return F, G, H, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(sigma_hat, r):\n",
    "    N = len(r)\n",
    "    return -0.5 * (N * np.log(2 * np.pi) \n",
    "                   + N * np.log(sigma_hat) \n",
    "                   + np.sum(np.log(r)) + N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func_likelihood(theta):\n",
    "    p = 3   # AR order\n",
    "    q = 2   # MA order\n",
    "    a = theta[:p]\n",
    "    b = theta[p:p+q]\n",
    "    k = max(p, q + 1)\n",
    "    \n",
    "    F, G, H, Q = initialize_FGHQ(a, b)\n",
    "\n",
    "    # Initialize values\n",
    "    x = np.zeros((k, 1))\n",
    "    V = np.eye(k) * 100\n",
    "    e = np.zeros((N, 1))\n",
    "    r = np.zeros((N, 1))\n",
    "\n",
    "    # Implement Kalman filter\n",
    "    for t in range(N):\n",
    "        # Predict one-step-ahead state predictive density of x_{t}\n",
    "        x_predict = F @ x\n",
    "        V_predict = F @ V @ F.T + G @ G.T\n",
    "\n",
    "        # Compute forecast error and one-step-ahead predictive variance\n",
    "        e[t] = y[t] - (H @ x_predict).item()\n",
    "        r[t] = (H @ V_predict @ H.T).item()\n",
    "\n",
    "        # Kalman gain\n",
    "        K = V_predict @ H.T / r[t]\n",
    "\n",
    "        # Update current state and covariance\n",
    "        x = x_predict + K * e[t]\n",
    "        V = (np.eye(k) - K @ H) @ V_predict\n",
    "\n",
    "    sigma_hat = np.sum(e**2 / r) / N\n",
    "    log_lik = log_likelihood(sigma_hat, r)\n",
    "\n",
    "    return -log_lik  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: [ 0.81943818 -0.32621222  0.20659743 -0.08235878  0.41224443]\n",
      "Negative log-likelihood: 1404.6619274394807\n"
     ]
    }
   ],
   "source": [
    "theta_start = [0.5, -0.3, 0.2, 0.4, -0.2]\n",
    "\n",
    "# Minimize negative log-likelihood\n",
    "result = minimize(obj_func_likelihood, theta_start, method='BFGS')\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated parameters:\", result.x)\n",
    "print(\"Negative log-likelihood:\", result.fun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
