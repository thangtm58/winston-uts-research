{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib, time, copy\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy.stats as sps_autograd\n",
    "from autograd import grad, hessian\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate ARMA data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulate ARMA(1, 1) model\n",
    "\"\"\"\n",
    "\n",
    "# Define AR and MA coefficients\n",
    "ar = np.array([1, -0.5])  \n",
    "ma = np.array([1, 0.4])        \n",
    "\n",
    "# Create ARMA process object\n",
    "arma_process = ArmaProcess(ar, ma)\n",
    "\n",
    "# Simulate 10000 samples\n",
    "N = 1000\n",
    "y = arma_process.generate_sample(nsample=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karman Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef initialize_FGHQ(a, b):\\n\\n    Construct the state-space matrices F, G, H for an ARMA(p, q) model.\\n\\n    Parameters:\\n    - p: int, order of the AR component\\n    - q: int, order of the MA component\\n    - a: list or np.array of AR coefficients [a1, a2, ..., ap]\\n    - b: list or np.array of MA coefficients [b1, b2, ..., bq]\\n\\n    Returns:\\n    - F: state transition matrix of shape (k, k)\\n    - G: noise coefficient matrix of shape (k, 1)\\n    - H: observation matrix of shape (1, k)\\n    - Q: covariance identity matrix of shape (k, k)\\n\\n    p = len(a)\\n    q = len(b)\\n    k = max(p, q + 1)  # dimension of the state vector\\n    F = np.zeros((k, k))\\n    G = np.zeros((k, 1))\\n    H = np.zeros((1, k))\\n\\n    # Fill the first column of F with AR coefficients\\n    for i in range(p):\\n        F[i, 0] = a[i]\\n\\n    # Fill the lower subdiagonal of F with 1s (shifting the state)\\n    for i in range(k - 1):\\n        F[i, i + 1] = 1\\n\\n    # Fill G with negative MA coefficients, first element = 1\\n    for i in range(q):\\n        G[i+1, 0] = -b[i]\\n    G[0, 0] = 1  # first element always set to 1\\n\\n    # Matrix H: only first element is 1\\n    H[0, 0] = 1\\n\\n    # Initialize covariance matrix Q as identity matrix\\n    Q = np.eye(k)\\n\\n    return F, G, H, Q\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def initialize_FGHQ(a, b):\n",
    "    \n",
    "    Construct the state-space matrices F, G, H for an ARMA(p, q) model.\n",
    "\n",
    "    Parameters:\n",
    "    - p: int, order of the AR component\n",
    "    - q: int, order of the MA component\n",
    "    - a: list or np.array of AR coefficients [a1, a2, ..., ap]\n",
    "    - b: list or np.array of MA coefficients [b1, b2, ..., bq]\n",
    "\n",
    "    Returns:\n",
    "    - F: state transition matrix of shape (k, k)\n",
    "    - G: noise coefficient matrix of shape (k, 1)\n",
    "    - H: observation matrix of shape (1, k)\n",
    "    - Q: covariance identity matrix of shape (k, k)\n",
    "    \n",
    "    p = len(a)\n",
    "    q = len(b)\n",
    "    k = max(p, q + 1)  # dimension of the state vector\n",
    "    F = np.zeros((k, k))\n",
    "    G = np.zeros((k, 1))\n",
    "    H = np.zeros((1, k))\n",
    "\n",
    "    # Fill the first column of F with AR coefficients\n",
    "    for i in range(p):\n",
    "        F[i, 0] = a[i]\n",
    "\n",
    "    # Fill the lower subdiagonal of F with 1s (shifting the state)\n",
    "    for i in range(k - 1):\n",
    "        F[i, i + 1] = 1\n",
    "\n",
    "    # Fill G with negative MA coefficients, first element = 1\n",
    "    for i in range(q):\n",
    "        G[i+1, 0] = -b[i]\n",
    "    G[0, 0] = 1  # first element always set to 1\n",
    "\n",
    "    # Matrix H: only first element is 1\n",
    "    H[0, 0] = 1\n",
    "\n",
    "    # Initialize covariance matrix Q as identity matrix\n",
    "    Q = np.eye(k)\n",
    "\n",
    "    return F, G, H, Q\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_FGHQ(a, b):\n",
    "    \"\"\"\n",
    "    Construct the state-space matrices F, G, H for an ARMA(p, q) model.\n",
    "\n",
    "    Parameters:\n",
    "    - a: list or np.array of AR coefficients [a1, a2, ..., ap]\n",
    "    - b: list or np.array of MA coefficients [b1, b2, ..., bq]\n",
    "\n",
    "    Returns:\n",
    "    - F: state transition matrix of shape (k, k)\n",
    "    - G: noise coefficient matrix of shape (k, 1)\n",
    "    - H: observation matrix of shape (1, k)\n",
    "    - Q: covariance identity matrix of shape (k, k)\n",
    "    - dF: derivative of F with respect to theta of shape (l, k, k)\n",
    "    - dG: derivative of G with respect to theta of shape (l, k, 1)\n",
    "    \"\"\"\n",
    "    p = len(a)\n",
    "    q = len(b)\n",
    "    k = max(p, q + 1)  # dimension of the state vector\n",
    "    F = np.zeros((k, k))\n",
    "    G = np.zeros((k, 1))\n",
    "    H = np.zeros((1, k))\n",
    "\n",
    "    # Fill the first column of F with AR coefficients\n",
    "    for i in range(p):\n",
    "        F[i, 0] = a[i]\n",
    "\n",
    "    # Fill the lower subdiagonal of F with 1s (shifting the state)\n",
    "    for i in range(k - 1):\n",
    "        F[i, i + 1] = 1\n",
    "\n",
    "    # Fill G with negative MA coefficients, first element = 1\n",
    "    for i in range(q):\n",
    "        G[i+1, 0] = -b[i]\n",
    "    G[0, 0] = 1  # first element always set to 1\n",
    "\n",
    "    # Matrix H: only first element is 1\n",
    "    H[0, 0] = 1\n",
    "\n",
    "    # Initialize covariance matrix Q as identity matrix\n",
    "    Q = np.eye(k)\n",
    "\n",
    "    # Compute derivatives of F and G with respect to theta\n",
    "    dF = np.zeros((k, k, k))\n",
    "    dF[0, 0, 0] = 1 # ARMA(1,1)\n",
    "\n",
    "    dG = np.zeros((k, k, 1))\n",
    "    dG[1, 1, 0] = -1 # ARMA(1,1)\n",
    "\n",
    "    return F, G, H, Q, dF, dG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(sigma2_hat, r):\n",
    "    N = len(r)\n",
    "    return -0.5 * (N * np.log(2 * np.pi) \n",
    "                   + N * np.log(sigma2_hat) \n",
    "                   + np.sum(np.log(r)) + N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def karman_filter_arma(theta):\n",
    "    p = 1   # AR order\n",
    "    q = 1   # MA order\n",
    "    a = theta[:p]\n",
    "    b = theta[p:p+q]\n",
    "    k = max(p, q + 1)\n",
    "    \n",
    "    F, G, H, Q, dF, dG = initialize_FGHQ(a, b)\n",
    "\n",
    "    # Initialize values\n",
    "    x = np.zeros((k, 1))\n",
    "    V = np.eye(k) * 100\n",
    "    e = np.zeros((N, 1))\n",
    "    r = np.zeros((N, 1))\n",
    "\n",
    "    # Implement Kalman filter\n",
    "    for t in range(N):\n",
    "        # Predict one-step-ahead state predictive density of x_{t}\n",
    "        x_predict = F @ x\n",
    "        V_predict = F @ V @ F.T + G @ G.T\n",
    "\n",
    "        # Compute forecast error and one-step-ahead predictive variance\n",
    "        e[t] = y[t] - (H @ x_predict).item()\n",
    "        r[t] = (H @ V_predict @ H.T).item()\n",
    "\n",
    "        # Kalman gain\n",
    "        K = V_predict @ H.T / r[t]\n",
    "\n",
    "        # Update current state and covariance\n",
    "        x = x_predict + K * e[t]\n",
    "        V = (np.eye(k) - K @ H) @ V_predict\n",
    "\n",
    "    sigma2_hat = np.sum(e**2 / r) / N\n",
    "\n",
    "    return sigma2_hat, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func_likelihood(theta):\n",
    "    sigma2_hat, r = karman_filter_arma(theta)\n",
    "    log_lik = log_likelihood(sigma2_hat, r)\n",
    "\n",
    "    return -log_lik  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: [ 0.54290688 -0.35020954]\n",
      "Negative log-likelihood: 1390.6811877545556\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test the log-likelihood function\n",
    "\"\"\"\n",
    "\n",
    "theta_start = [0.1, 0.1]\n",
    "\n",
    "# Minimize negative log-likelihood\n",
    "result = minimize(obj_func_likelihood, theta_start, method='BFGS')\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated parameters:\", result.x)\n",
    "print(\"Negative log-likelihood:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_initial_V_and_dV(a, b, sigma2):\n",
    "    \"\"\"\n",
    "    Tính toán V ban đầu và dV/d(theta) ban đầu.\n",
    "    Thực thi các phương trình từ mục 3.3.2 của tài liệu.\n",
    "    \"\"\"\n",
    "    p, q = 1, 1\n",
    "    k = max(p, q + 1)  \n",
    "\n",
    "    # 1. Tính hàm đáp ứng xung g_k (Eq. 52)\n",
    "    g = np.zeros(k + 1)\n",
    "    g[0] = 1.0\n",
    "    g[1] = a - b\n",
    "    g[2] = a * g[1]\n",
    "\n",
    "    C = np.zeros(k + 1)\n",
    "    C[0] = sigma2 * (1 - 2 * a * b + b**2) / (1 - a**2)\n",
    "    C[1] = a * C[0] - sigma2 * b\n",
    "    C[2] = a * C[1]\n",
    "\n",
    "    V = np.zeros((k, k))\n",
    "    V[0, 0] = C[0]\n",
    "    V[0, 1] = V[1, 0] = - b * g[0]\n",
    "    V[1, 1] = b**2 * sigma2\n",
    "\n",
    "    dV = np.zeros((k, k, k))\n",
    "    dV[0, 0, 0] = (2 * sigma2 * (a-b) * (1 - a*b)) / (1 - a**2)**2\n",
    "    dV[0, 0, 1] = 0\n",
    "    dV[0, 1, 0] = 0\n",
    "    dV[0, 1, 1] = 0\n",
    "    dV[1, 0, 0] = 2 * sigma2 * (b-a) / (1 - a**2)\n",
    "    dV[1, 0, 1] = -1\n",
    "    dV[1, 1, 0] = -1\n",
    "    dV[1, 1, 1] = 2 * b * sigma2\n",
    "\n",
    "    return V, dV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_obj_func_likelihood(theta):\n",
    "    \"\"\"\n",
    "    Implement the gradient of the log-likelihood function for ARMA(1,1) model.\n",
    "    \"\"\"\n",
    "    \n",
    "    a = theta[0]\n",
    "    b = theta[1]\n",
    "    k = 2\n",
    "\n",
    "    # Initialize the state-space matrices\n",
    "    F, G, H, Q, dF, dG = initialize_FGHQ(np.array([a]), np.array([b]))\n",
    "    \n",
    "    # Initialize the x and V matrices\n",
    "    V, dV = compute_initial_V_and_dV(a, b, 1)\n",
    "    x = np.zeros((k, 1))\n",
    "    dx = np.zeros((2, 2, 1))\n",
    "    e = np.zeros((N, 1))\n",
    "    r = np.zeros((N, 1))\n",
    "    de = np.zeros((N, 2))\n",
    "    dr = np.zeros((N, 2))\n",
    "\n",
    "    # \n",
    "    for t in range(N):\n",
    "        # 1. Predict\n",
    "        # Predict one-step-ahead state predictive density of x_{t}\n",
    "        x_predict = F @ x\n",
    "        V_predict = F @ V @ F.T + G @ G.T\n",
    "\n",
    "        # Compute forecast error and one-step-ahead predictive variance\n",
    "        e[t] = y[t] - (H @ x_predict).item()\n",
    "        r[t] = (H @ V_predict @ H.T).item()\n",
    "\n",
    "\n",
    "        # Kalman filter for gradient\n",
    "        dx_predict = F @ dx + dF @ x\n",
    "        dV_predict = F @ dV @ F.T + dF @ V @ F.T + F @ V @ dF.T + dG @ G.T  # + G @ dG.T\n",
    "\n",
    "        de_t = -H @ dx_predict\n",
    "        dr_t = H @ dV_predict @ H.T\n",
    "\n",
    "\n",
    "        # 2. Update\n",
    "        # Kalman gain\n",
    "        K = V_predict @ H.T / r[t]\n",
    "\n",
    "        # Update current state and covariance\n",
    "        x = x_predict + K * e[t]\n",
    "        V = (np.eye(k) - K @ H) @ V_predict\n",
    "\n",
    "        dK = (dV_predict @ H.T / r[t]) - (V_predict @ H.T / r[t]**2 * dr[t])\n",
    "        dx = dx_predict + K @ de_t + dK * e[t]\n",
    "        dV = dV_predict - dK * H @ V_predict - K @ H @ dV_predict\n",
    "\n",
    "        # Store value de and dr \n",
    "        de[t] = de_t.flatten()\n",
    "        dr[t] = dr_t.flatten()\n",
    "\n",
    "    # === 3. Tính Gradient cuối cùng ===\n",
    "    sigma2_hat = np.sum(e**2 / r) / N\n",
    "    \n",
    "    grad = -0.5 * sum(dr / r) - (1/sigma2_hat) * sum(de * e / r) + (1/(2*sigma2_hat)) * sum(dr * e**2 / r**2)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4,) into shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m theta_start = [\u001b[32m0.1\u001b[39m, \u001b[32m0.1\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Minimize negative log-likelihood\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func_likelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBFGS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_obj_func_likelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                  \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-04\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdisp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEstimated parameters:\u001b[39m\u001b[33m\"\u001b[39m, result.x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_minimize.py:733\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    731\u001b[39m     res = _minimize_cg(fun, x0, args, jac, callback, **options)\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mbfgs\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     res = \u001b[43m_minimize_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    735\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    736\u001b[39m                              **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1393\u001b[39m, in \u001b[36m_minimize_bfgs\u001b[39m\u001b[34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, c1, c2, hess_inv0, **unknown_options)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1391\u001b[39m     maxiter = \u001b[38;5;28mlen\u001b[39m(x0) * \u001b[32m200\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1393\u001b[39m sf = \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m f = sf.fun\n\u001b[32m   1397\u001b[39m myfprime = sf.grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_optimize.py:291\u001b[39m, in \u001b[36m_prepare_scalar_function\u001b[39m\u001b[34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[39m\n\u001b[32m    287\u001b[39m     bounds = (-np.inf, np.inf)\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m sf = \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:232\u001b[39m, in \u001b[36mScalarFunction.__init__\u001b[39m\u001b[34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28mself\u001b[39m._wrapped_grad, \u001b[38;5;28mself\u001b[39m._ngev = _wrapper_grad(\n\u001b[32m    227\u001b[39m     grad,\n\u001b[32m    228\u001b[39m     fun=\u001b[38;5;28mself\u001b[39m._wrapped_fun,\n\u001b[32m    229\u001b[39m     args=args,\n\u001b[32m    230\u001b[39m     finite_diff_options=finite_diff_options\n\u001b[32m    231\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Hessian evaluation\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(hess):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:307\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/study/UTS/35112 Mathematical Research/winston-uts-research/venv/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:42\u001b[39m, in \u001b[36m_wrapper_grad.<locals>.wrapped\u001b[39m\u001b[34m(x, **kwds)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(x, **kwds):\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# kwds present to give function same signature as numdiff variant\u001b[39;00m\n\u001b[32m     41\u001b[39m     ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.atleast_1d(\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mgrad_obj_func_likelihood\u001b[39m\u001b[34m(theta)\u001b[39m\n\u001b[32m     52\u001b[39m     dV = dV_predict - dK * H @ V_predict - K @ H @ dV_predict\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Store value de and dr \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mde\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m = de_t.flatten()\n\u001b[32m     56\u001b[39m     dr[t] = dr_t.flatten()\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# === 3. Tính Gradient cuối cùng ===\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: could not broadcast input array from shape (4,) into shape (2,)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test the log-likelihood function\n",
    "\"\"\"\n",
    "\n",
    "theta_start = [0.1, 0.1]\n",
    "\n",
    "# Minimize negative log-likelihood\n",
    "result = minimize(obj_func_likelihood, theta_start, method='BFGS', jac=grad_obj_func_likelihood,\n",
    "                  options={'gtol': 1e-04, 'maxiter': 1000, 'disp': True})\n",
    "\n",
    "# Print results\n",
    "print(\"Estimated parameters:\", result.x)\n",
    "print(\"Negative log-likelihood:\", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.3\n",
    "b = 0.5\n",
    "k = 2\n",
    "\n",
    "# Initialize the state-space matrices\n",
    "F, G, H, Q, dF, dG = initialize_FGHQ(np.array([a]), np.array([b]))\n",
    "\n",
    "# Initialize the x and V matrices\n",
    "V, dV = compute_initial_V_and_dV(a, b, 1)\n",
    "x = np.zeros((k, 1))\n",
    "dx = np.zeros((2, 2, 1))\n",
    "e = np.zeros((N, 1))\n",
    "r = np.zeros((N, 1))\n",
    "de = np.zeros((N, 2))\n",
    "dr = np.zeros((N, 2))\n",
    "\n",
    "    # \n",
    "t = 0\n",
    "# 1. Predict\n",
    "# Predict one-step-ahead state predictive density of x_{t}\n",
    "x_predict = F @ x\n",
    "V_predict = F @ V @ F.T + G @ G.T\n",
    "\n",
    "# Compute forecast error and one-step-ahead predictive variance\n",
    "e[t] = y[t] - (H @ x_predict).item()\n",
    "r[t] = (H @ V_predict @ H.T).item()\n",
    "\n",
    "\n",
    "# Kalman filter for gradient\n",
    "dx_predict = F @ dx + dF @ x\n",
    "dV_predict = F @ dV @ F.T + dF @ V @ F.T + F @ V @ dF.T + dG @ G.T  # + G @ dG.T\n",
    "\n",
    "de_t = -H @ dx_predict\n",
    "dr_t = H @ dV_predict @ H.T\n",
    "\n",
    "\n",
    "# 2. Update\n",
    "# Kalman gain\n",
    "K = V_predict @ H.T / r[t]\n",
    "\n",
    "# Update current state and covariance\n",
    "x = x_predict + K * e[t]\n",
    "V = (np.eye(k) - K @ H) @ V_predict\n",
    "\n",
    "dK = (dV_predict @ H.T / r[t]) - (V_predict @ H.T / r[t]**2 * dr[t])\n",
    "dx = dx_predict + K @ de_t + dK * e[t]\n",
    "dV = dV_predict - dK * H @ V_predict - K @ H @ dV_predict\n",
    "\n",
    "# Store value de and dr \n",
    "de[t] = de_t.flatten()\n",
    "dr[t] = dr_t.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41057843,  0.43956044])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de[t]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
